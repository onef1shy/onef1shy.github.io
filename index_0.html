<!doctype html>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
   <!--  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JZYE5C90XX"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-JZYE5C90XX');
    </script>
-->
    <title>Jun CEN&nbsp;&bull;&nbsp;岑俊</title>

    <meta name="author" content="Jun CEN">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="This is the academic homepage of Jun CEN">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/leon.png">
    
    <!-- Make all the links contained on this page to be opened with a new page. -->
    <base target="_blank" />
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
            <td style="padding:0px">

                <!-- ########## About ME ########## -->                
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p style="text-align:center">
                        <name>Jun CEN</name>
                    </p>
                    <p>
                        I am a Ph.D. student at the
                        <a href="http://ri.ust.hk">Robotics Institute</a>, <a href="https://www.ust.hk">The Hong Kong University of Science and Technology</a>,
                        where I work on computer vision and autonomous driving under the supervision of <a href="https://cqf.io/">Prof. Qifeng Chen</a> and <a href="https://research.monash.edu/en/persons/michael-wang-2">Prof. Michael Yu Wang</a>. Now I work as a Research Intern at <a href="https://damo.alibaba.com/">DAMO Academy, Alibaba Group</a>.
                    </p>
                    <p>
I got my MSc degree of Mechanical Engineering in HKUST between 2019-2020. At the mean time, I worked as a Research Assistant in <a href="https://crai.cuhk.edu.cn/"> Robotics and Artificial Intelligence Laboratory, CUHK(SZ).</a>
   
                        Before that, I graduated from 
                        <a href="https://www.zju.edu.cn/">Zhejiang University</a>
                        in 2019 with a bachelor's degree in Mechatronics. 
                    </p>
                    <p style="text-align:center"> 
                        <a href="mailto:jcenaa@connect.ust.hk">Email</a> &nbsp/&nbsp
                        <a href="https://scholar.google.com/citations?user=7SKAhBwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                        <a href="https://github.com/Jun-CEN">Github</a>&nbsp/&nbsp
                        <a href="work/Resume_Jun_CEN.pdf">CV</a>
                    </p>
                    </td>

                    <td style="padding:2.5%;width:40%;max-width:40%">
                    <a href="images/myself.jpg" title="Hi! I'm Haoran">
                        <img style="width:100%;max-width:100%" alt="profile photo" src="images/myself.jpg" class="hoverZoomLink">
                    </a>
                    </td>
                </tr>
                </tbody></table>


                <!-- ########## Section: Research Intersets ########## -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                    <heading>Research</heading>
                    <p>
My research lies in open-world perception systems of autonomous driving, including open-world semantic segmentation, 3D object detection, and 3D semantic segmentation, as well as distributed learning including federated learning and blockchain.
                        <!-- Representative papers are <span class="highlight">highlighted</span>. -->
                    </p>
                    </td>
                </tr>
                </tbody></table>
                
                <!-- ########## Section: Research Works ########## -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<!-- ##### ECCV 2022 #####-->
                    <tr>
                        <td style="padding:15px;width:25%;vertical-align:middle">
                            <img src="images/eccv2022.png" style="max-width:100%" alt="PiP architecture">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                        <img style="width: 35px" src="images/new.png">
                        <a href="prime/">
                            <papertitle>Open-world Semantic Segmentation for LIDAR Point Clouds</papertitle>
                        </a>
                        <br />
                        <strong>Jun Cen</strong>, Peng Yun, Shiwei Zhang, Junhao Cai, Di Luan, Michael Yu Wang, Ming Liu, Mingqian Tang
                        <br />
                        <br />
                        <em>European Conference on Computer Vision <strong>(ECCV 2022)</strong></em>, Tel Aviv, Israel.
                        <br />
                        <p>
                            <q>We propose the open-world semantic segmentation system in 3D LIDAR Point Cloud domain and use redundancy classifiers to solve the problem.</q>
                        </p>
                        <a href="https://arxiv.org/abs/2207.01452">arxiv</a> &nbsp/&nbsp
<a href="https://github.com/Jun-CEN/Open_world_3D_semantic_segmentation">code</a> &nbsp/&nbsp
                    </td>
                    </tr>
<!-- ##### 3DV 2021 #####-->
                    <tr>
                        <td style="padding:15px;width:25%;vertical-align:middle">
                            <img src="images/3dv_2021.png" style="max-width:100%" alt="PiP architecture">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                       
                        <a href="prime/">
                            <papertitle>Open-set 3D Object Detection</papertitle>
                        </a>
                        <br />
                        <strong>Jun Cen</strong>, Peng Yun, Junhao Cai, Michael Yu Wang, Ming Liu
                        <br />
                        <br />
                        <em>International Conference on 3D Vision <strong>(3DV 2021)</strong></em>, London, UK.
                        <br />
                        <p>
                            <q>We propose the open-set 3D object detector to detect both known objects as well as unknonw objects.</q>
                        </p>
                        <a href="https://arxiv.org/abs/2112.01135">arXiv</a>
                    </td>
                    </tr>
                    <!-- ##### ICCV 2021 #####-->
                    <tr>
                        <td style="padding:15px;width:25%;vertical-align:middle">
                            <img src="images/head_3.jpg" style="max-width:100%" alt="PiP architecture">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                       
                        <a href="prime/">
                            <papertitle>Deep Metric Learning for Open World Semantic Segmentation</papertitle>
                        </a>
                        <br />
                        <strong>Jun Cen</strong>, Peng Yun, Junhao Cai, Michael Yu Wang, Ming Liu
                        <br />
                        <br />
                        <em>International Conference on Computer Vision <strong>(ICCV 2021)</strong></em>, Montreal, Canada.  
                        <br />
                        <p> 
                            <q>Open-set segmentation detects unknown objects, then few-shot incremental learning is adopted to involve unknown objects into the knowledge base of the neural network.</q>
                        </p>
                        <a href="https://arxiv.org/abs/2108.04562">arXiv</a> &nbsp/&nbsp
                        <a href="https://github.com/Jun-CEN/Open-World-Semantic-Segmentation">code</a> &nbsp/&nbsp
                        <a href="https://youtu.be/t1vl7MzGb2Q"> video </a>
                        <!-- <span class="unavailable">code (to be released)</span> -->
                        </td>
                    </tr>
                    
                    <!-- ##### IROS 2021 #####-->
                    <tr>
                        <td style="padding:15px;width:25%;vertical-align:middle">
                            <img src="images/iros2021.png" style="max-width:100%" alt="PiP architecture">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="planning-informed-prediction/">
                            <papertitle>BORM: Bayesian Object Relation Model for Indoor Scene Recognition</papertitle>
                        </a>
                        <br />
                        Liguang Zhou, <strong>Jun Cen</strong>, Xingchao Wang, Zhenglong Sun, Tin Lun Lam, Yangsheng Xu
                        <br />
                        <br />
                        <em>International Conference on Intelligent Robots and Systems <strong>(IROS 2021)</strong></em>, Prague, Czech Republic.  
                        <br />
                        <p> 
                            <q>Improve the scene classification accuracy through considering discriminative object pairs.</q>
                        </p>
                        <a href="https://arxiv.org/abs/2108.00397">arXiv</a> &nbsp/&nbsp
                        <a href="https://github.com/Jun-CEN/BORM">code</a> &nbsp/&nbsp 
                        <a href="https://www.youtube.com/watch?v=8lHP-sdNRJ8"> video
                        </td>
                    </tr>

                </tbody></table>

                <!-- ########## Section: Service ########## -->
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                    <tr>
                      <td>
                        <heading>Service</heading>
                      </td>
                    </tr>
                </tbody></table>
                <table width="100%" align="center" border="0" cellpadding="20"><tbody>
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/ieee_ras_logo.png" style="max-width:100%">
                        </td>
                        <td width="75%" valign="center">
                            Reviewer for IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
                        </td>
                    </tr>        
                </tbody></table>
            
                <!-- ########## Tools: Visitor Locations Visualization ########## -->
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5mz7hnrbg3y&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
                <!-- ########## Last: Acknowledgment ########## -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                        <td style="padding:0px">
                            <p style="text-align:right;font-size:small;">
                                Made from
                                <a href="https://jonbarron.info/">Dr. Jon Barron</a>'s website design.
                            </p>
                        </td>
                    </tr>
                </tbody></table>

            </td>
        </tr>
    </tbody></table>
</body>



</html>
